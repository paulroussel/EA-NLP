{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "from cache import Cache\n",
    "\n",
    "cache=Cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cache.load('clean_df_complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_len'] = df['title'].apply(lambda x : len(x))\n",
    "df['description_len'] = df['description'].apply(lambda x : len(x))\n",
    "df['content_len'] = df['content'].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean title :  41.92821651227684 \n",
      "mean description :  156.9825001815334 \n",
      "mean content :  2638.949834545285\n",
      "\n",
      "ratio :  16.81047143148837  and  62.939711107735384\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean \n",
    "print('mean title : ',mean(df['title_len']),\n",
    "'\\nmean description : ',mean(df['description_len']),\n",
    "'\\nmean content : ',mean(df['content_len']))\n",
    "\n",
    "print('\\nratio : ',mean(df['content_len'])/mean(df['description_len']),' and ',mean(df['content_len'])/mean(df['title_len']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels  = cache.load('labels_96k')\n",
    "content_lsa = cache.load('feature_content_lsa_96k')\n",
    "description_lsa = cache.load('feature_description_lsa_96k')\n",
    "title_lsa = cache.load('feature_title_lsa_96k')\n",
    "content_w2v = cache.load('feature_content_w2v_96k')\n",
    "title_w2v = cache.load('feature_title_w2v_96k')\n",
    "description_w2v = cache.load('feature_description_w2v_96k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = []\n",
    "for i in range(len(labels)):\n",
    "    temp = [item for item in np.concatenate((content_lsa[i],description_lsa[i],title_lsa[i],content_w2v[i],title_w2v[i],description_w2v[i],labels['thematic_value'][i]),axis=None)]\n",
    "    if len(temp)==112:\n",
    "        XY+=[temp]\n",
    "XY = np.array(XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95495, 112)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10000)\n",
    "np.random.shuffle(XY)\n",
    "\n",
    "X = XY[:,:-1]\n",
    "Y = XY[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = (len(X)*8)//10\n",
    "\n",
    "X_train = X[:split,:]\n",
    "X_test = X[split+1:,:]\n",
    "Y_train = Y[:split]\n",
    "Y_test = Y[split+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d4c717df5760>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "forest = rfc(n_estimators=200, max_depth=5,random_state=0)\n",
    "forest.fit(X_train, Y_train)\n",
    "forest.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score pour la classe 0 est de 0.9042831710126715 %\n",
      "le score pour la classe 1 est de 0.8988899361189653 %\n",
      "le score pour la classe 2 est de 0.9369567493978427 %\n",
      "le score pour la classe 3 est de 0.8756937899256466 %\n",
      "le score pour la classe 4 est de 0.9104094669598911 %\n",
      "le score pour la classe 5 est de 0.9224526128390408 %\n",
      "le score pour la classe 6 est de 0.9317205990156038 %\n",
      "le score pour la classe 7 est de 0.9360142423290397 %\n",
      "le score pour la classe 8 est de 0.9582678814535553 %\n",
      "le score pour la classe 9 est de 0.9452822285056027 %\n",
      "le score pour la classe 10 est de 0.9451775054979579 %\n"
     ]
    }
   ],
   "source": [
    "forests = {}\n",
    "scores = []\n",
    "for i in range(11):\n",
    "    \n",
    "    Y_train_temp = np.array([int(item==i) for item in Y_train])\n",
    "    Y_test_temp = np.array([int(item==i) for item in Y_test])\n",
    "    \n",
    "    \n",
    "    forests[i] = rfc(n_estimators=200, max_depth=5,random_state=0)\n",
    "    forests[i].fit(X_train, Y_train_temp)\n",
    "    scores.append(forests[i].score(X_test, Y_test_temp))\n",
    "    print('le score pour la classe ' + str(i) + ' est de ' + str(scores[i]) + ' %')\n",
    "\n",
    "cache.save(forests,'forests_try2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for i in range(11):\n",
    "    classes.append(forests[i].predict(X_test))\n",
    "\n",
    "classes = np.array(classes).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "for item in classes:\n",
    "    test.append(sum(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1845219394701016"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auges\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import activations\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "from time import clock\n",
    "from tensorflow.keras.utils import normalize, to_categorical\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_cat = to_categorical(Y)\n",
    "Y_train_cat = Y_cat[:split,:]\n",
    "Y_test_cat = Y_cat[split+1:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76396 samples, validate on 19098 samples\n",
      "Epoch 1/20\n",
      "76396/76396 [==============================] - 4s 47us/step - loss: 1.1628 - acc: 0.5931 - val_loss: 1.0907 - val_acc: 0.6179\n",
      "Epoch 2/20\n",
      "76396/76396 [==============================] - 3s 44us/step - loss: 1.0757 - acc: 0.6214 - val_loss: 1.0694 - val_acc: 0.6191\n",
      "Epoch 3/20\n",
      "76396/76396 [==============================] - 3s 43us/step - loss: 1.0530 - acc: 0.6302 - val_loss: 1.0460 - val_acc: 0.6318\n",
      "Epoch 4/20\n",
      "76396/76396 [==============================] - 3s 44us/step - loss: 1.0385 - acc: 0.6350 - val_loss: 1.0380 - val_acc: 0.6349\n",
      "Epoch 5/20\n",
      "76396/76396 [==============================] - 3s 42us/step - loss: 1.0281 - acc: 0.6388 - val_loss: 1.0352 - val_acc: 0.6357\n",
      "Epoch 6/20\n",
      "76396/76396 [==============================] - 3s 43us/step - loss: 1.0203 - acc: 0.6403 - val_loss: 1.0223 - val_acc: 0.6414\n",
      "Epoch 7/20\n",
      "76396/76396 [==============================] - 3s 42us/step - loss: 1.0129 - acc: 0.6435 - val_loss: 1.0206 - val_acc: 0.6396\n",
      "Epoch 8/20\n",
      "76396/76396 [==============================] - 3s 42us/step - loss: 1.0070 - acc: 0.6459 - val_loss: 1.0130 - val_acc: 0.6465\n",
      "Epoch 9/20\n",
      "76396/76396 [==============================] - 3s 42us/step - loss: 1.0023 - acc: 0.6473 - val_loss: 1.0069 - val_acc: 0.6476\n",
      "Epoch 10/20\n",
      "76396/76396 [==============================] - 3s 41us/step - loss: 0.9973 - acc: 0.6486 - val_loss: 1.0062 - val_acc: 0.6475\n",
      "Epoch 11/20\n",
      "76396/76396 [==============================] - 3s 43us/step - loss: 0.9934 - acc: 0.6506 - val_loss: 1.0029 - val_acc: 0.6494\n",
      "Epoch 12/20\n",
      "76396/76396 [==============================] - 3s 43us/step - loss: 0.9896 - acc: 0.6517 - val_loss: 0.9994 - val_acc: 0.6502\n",
      "Epoch 13/20\n",
      "76396/76396 [==============================] - 3s 42us/step - loss: 0.9858 - acc: 0.6525 - val_loss: 0.9939 - val_acc: 0.6517\n",
      "Epoch 14/20\n",
      "76396/76396 [==============================] - 3s 43us/step - loss: 0.9825 - acc: 0.6538 - val_loss: 0.9941 - val_acc: 0.6530\n",
      "Epoch 15/20\n",
      "76396/76396 [==============================] - 4s 49us/step - loss: 0.9800 - acc: 0.6548 - val_loss: 0.9895 - val_acc: 0.6538\n",
      "Epoch 16/20\n",
      "76396/76396 [==============================] - 3s 43us/step - loss: 0.9767 - acc: 0.6557 - val_loss: 0.9903 - val_acc: 0.6528\n",
      "Epoch 17/20\n",
      "76396/76396 [==============================] - 3s 44us/step - loss: 0.9743 - acc: 0.6570 - val_loss: 0.9900 - val_acc: 0.6551\n",
      "Epoch 18/20\n",
      "76396/76396 [==============================] - 3s 43us/step - loss: 0.9721 - acc: 0.6564 - val_loss: 0.9843 - val_acc: 0.6554\n",
      "Epoch 19/20\n",
      "76396/76396 [==============================] - 3s 45us/step - loss: 0.9695 - acc: 0.6595 - val_loss: 0.9850 - val_acc: 0.6561\n",
      "Epoch 20/20\n",
      "76396/76396 [==============================] - 3s 45us/step - loss: 0.9672 - acc: 0.6597 - val_loss: 0.9838 - val_acc: 0.6561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fdd85343c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=f'project-{int(time.time())}'\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "\n",
    "model.add(Dense(11,activation='softmax'))\n",
    "\n",
    "ada = keras.optimizers.Adagrad()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=ada,\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(X_train, Y_train_cat, batch_size=32, epochs=20, validation_data=(X_test, Y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score pour la classe 0 est de \n",
      "loss : 0.1386084643717598\n",
      "accuracy : 0.9480573882144313\n",
      "le score pour la classe 1 est de \n",
      "loss : 0.16030778272487267\n",
      "accuracy : 0.9324536600379073\n",
      "le score pour la classe 2 est de \n",
      "loss : 0.06823296725620448\n",
      "accuracy : 0.9779558068907739\n",
      "le score pour la classe 3 est de \n",
      "loss : 0.253130033551392\n",
      "accuracy : 0.8916640485665076\n",
      "le score pour la classe 4 est de \n",
      "loss : 0.20240175108726594\n",
      "accuracy : 0.9130275421572526\n",
      "le score pour la classe 5 est de \n",
      "loss : 0.11758523452326738\n",
      "accuracy : 0.9587914964917792\n",
      "le score pour la classe 6 est de \n",
      "loss : 0.17298617058188107\n",
      "accuracy : 0.9365378573672636\n",
      "le score pour la classe 7 est de \n",
      "loss : 0.1517144234246116\n",
      "accuracy : 0.9416692847480997\n",
      "le score pour la classe 8 est de \n",
      "loss : 0.05515359155784956\n",
      "accuracy : 0.9799455439985728\n",
      "le score pour la classe 9 est de \n",
      "loss : 0.11919058477183214\n",
      "accuracy : 0.9537124305835556\n",
      "le score pour la classe 10 est de \n",
      "loss : 0.13042612653781585\n",
      "accuracy : 0.9529793695300421\n"
     ]
    }
   ],
   "source": [
    "NNs = {}\n",
    "scores_NN = []\n",
    "for i in range(11):\n",
    "    \n",
    "    Y_train_temp_cat = to_categorical(np.array([int(item==i) for item in Y_train]))\n",
    "    Y_test_temp_cat = to_categorical(np.array([int(item==i) for item in Y_test]))\n",
    "       \n",
    "    \n",
    "    NNs[i]=Sequential()\n",
    "\n",
    "    NNs[i].add(Dense(32, activation='relu'))\n",
    "    NNs[i].add(Dense(256,activation='relu'))\n",
    "    NNs[i].add(Dense(256,activation='relu'))\n",
    "\n",
    "    NNs[i].add(Dense(2,activation='softmax'))\n",
    "\n",
    "    ada = keras.optimizers.Adagrad()\n",
    "\n",
    "    NNs[i].compile(loss='categorical_crossentropy',\n",
    "                  optimizer=ada,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    NNs[i].fit(X_train, Y_train_temp_cat, batch_size=32, epochs=10, validation_data=(X_test, Y_test_temp_cat),verbose=False)\n",
    "    \n",
    "    scores_NN.append(NNs[i].evaluate(X_test, Y_test_temp_cat,verbose=False))\n",
    "    \n",
    "    print('le score pour la classe ' + str(i) + ' est de \\nloss : ' + str(scores_NN[i][0]) + '\\naccuracy : ' + str(scores_NN[i][1]))\n",
    "\n",
    "    \n",
    "cache.save(NNs,'NNs_try1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_NN = []\n",
    "for i in range(11):\n",
    "    probas_NN.append(NNs[i].predict(X_test)[:,1])\n",
    "\n",
    "probas_NN = np.array(probas_NN).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12311041, 0.00144824, 0.03539392, 0.29005042, 0.21916789,\n",
       "       0.01995905, 0.03099126, 0.07595886, 0.00081773, 0.0317897 ,\n",
       "       0.04784445], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas_NN[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_NN = np.array([np.argmax(probas_NN[i]) for i in range(len(probas_NN))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12637"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(classes_NN == Y_test)/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
