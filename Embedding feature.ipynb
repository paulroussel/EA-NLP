{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cache import Cache\n",
    "cache=Cache()\n",
    "\n",
    "df = cache.load('dataframe_with_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flair.embeddings import DocumentLSTMEmbeddings,BertEmbeddings, WordEmbeddings, CharacterEmbeddings, ELMoEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings,Sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import preprocessing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features_flair_embeddings(contents):\n",
    "    \n",
    "    #contents = list(df['content'])\n",
    "    \n",
    "    #Il faut choisir ici en commantant les embedding que l'on veut \n",
    "    # initialize the word embeddings\n",
    "    glove_embedding = WordEmbeddings('fr')\n",
    "    flair_forward_embedding = FlairEmbeddings('french-forward')\n",
    "    flair_backward_embedding = FlairEmbeddings('french-backward')\n",
    "    #elmo_embedding = ELMoEmbeddings()\n",
    "    #character_embeddings = CharacterEmbeddings()\n",
    "    \n",
    "    #marche pas pour les long textes\n",
    "    #embedding = BertEmbeddings()\n",
    "\n",
    "    # initialize the document embeddings, mode = mean\n",
    "    document_embeddings = DocumentPoolEmbeddings([glove_embedding], mode='mean')\n",
    "    #document_lstm_embeddings = DocumentRNNEmbeddings([embedding,flair_backward_embedding, flair_forward_embedding], rnn_type='LSTM')\n",
    "    \n",
    "    flair_embeddings_contents = []\n",
    "    counter = 0\n",
    "    for i in range(len(contents)):\n",
    "        doc = contents[i]\n",
    "        if contents[i] = ' ':\n",
    "            doc = ' '\n",
    "            \n",
    "        sentence = Sentence(doc)\n",
    "        document_embeddings.embed(sentence)\n",
    "        \n",
    "        flair_embeddings_contents.append(sentence.get_embedding().numpy())\n",
    "        counter += 1\n",
    "        if counter % 100 == True:\n",
    "            print (counter, \"training examples processsed\")\n",
    "\n",
    "\n",
    "    return(flair_embeddings_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La fonction ne marche pas quand la liste comprend des string vides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training examples processsed\n",
      "101 training examples processsed\n",
      "201 training examples processsed\n",
      "301 training examples processsed\n",
      "401 training examples processsed\n",
      "501 training examples processsed\n",
      "601 training examples processsed\n",
      "701 training examples processsed\n",
      "801 training examples processsed\n",
      "901 training examples processsed\n",
      "1001 training examples processsed\n",
      "1101 training examples processsed\n",
      "1201 training examples processsed\n",
      "1301 training examples processsed\n",
      "1401 training examples processsed\n",
      "1501 training examples processsed\n",
      "1601 training examples processsed\n",
      "1701 training examples processsed\n",
      "1801 training examples processsed\n",
      "1901 training examples processsed\n",
      "2001 training examples processsed\n",
      "2101 training examples processsed\n",
      "2201 training examples processsed\n",
      "2301 training examples processsed\n",
      "2401 training examples processsed\n",
      "2501 training examples processsed\n",
      "2601 training examples processsed\n",
      "2701 training examples processsed\n",
      "2801 training examples processsed\n",
      "2901 training examples processsed\n",
      "3001 training examples processsed\n",
      "3101 training examples processsed\n",
      "3201 training examples processsed\n",
      "3301 training examples processsed\n",
      "3401 training examples processsed\n",
      "3501 training examples processsed\n",
      "3601 training examples processsed\n",
      "3701 training examples processsed\n",
      "3801 training examples processsed\n",
      "3901 training examples processsed\n",
      "4001 training examples processsed\n",
      "4101 training examples processsed\n",
      "4201 training examples processsed\n",
      "4301 training examples processsed\n",
      "4401 training examples processsed\n",
      "4501 training examples processsed\n",
      "4601 training examples processsed\n",
      "4701 training examples processsed\n",
      "4801 training examples processsed\n",
      "4901 training examples processsed\n",
      "5001 training examples processsed\n",
      "5101 training examples processsed\n",
      "5201 training examples processsed\n",
      "5301 training examples processsed\n",
      "5401 training examples processsed\n",
      "5501 training examples processsed\n",
      "5601 training examples processsed\n",
      "5701 training examples processsed\n",
      "5801 training examples processsed\n",
      "5901 training examples processsed\n",
      "6001 training examples processsed\n",
      "6101 training examples processsed\n",
      "6201 training examples processsed\n",
      "6301 training examples processsed\n",
      "6401 training examples processsed\n",
      "6501 training examples processsed\n",
      "6601 training examples processsed\n",
      "6701 training examples processsed\n",
      "6801 training examples processsed\n",
      "6901 training examples processsed\n",
      "7001 training examples processsed\n",
      "7101 training examples processsed\n",
      "7201 training examples processsed\n",
      "7301 training examples processsed\n",
      "7401 training examples processsed\n",
      "7501 training examples processsed\n",
      "7601 training examples processsed\n",
      "7701 training examples processsed\n",
      "7801 training examples processsed\n",
      "7901 training examples processsed\n",
      "8001 training examples processsed\n"
     ]
    }
   ],
   "source": [
    "features_embedding_titles = features_flair_embeddings(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cache.save(features_embedding_titles,'features_embedding_titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training examples processsed\n",
      "101 training examples processsed\n",
      "201 training examples processsed\n",
      "301 training examples processsed\n",
      "401 training examples processsed\n",
      "501 training examples processsed\n",
      "601 training examples processsed\n",
      "701 training examples processsed\n",
      "801 training examples processsed\n",
      "901 training examples processsed\n",
      "1001 training examples processsed\n",
      "1101 training examples processsed\n",
      "1201 training examples processsed\n",
      "1301 training examples processsed\n",
      "1401 training examples processsed\n",
      "1501 training examples processsed\n",
      "1601 training examples processsed\n",
      "1701 training examples processsed\n",
      "1801 training examples processsed\n",
      "1901 training examples processsed\n",
      "2001 training examples processsed\n",
      "2101 training examples processsed\n",
      "2201 training examples processsed\n",
      "2301 training examples processsed\n",
      "2401 training examples processsed\n",
      "2501 training examples processsed\n",
      "2601 training examples processsed\n",
      "2701 training examples processsed\n",
      "2801 training examples processsed\n",
      "2901 training examples processsed\n",
      "3001 training examples processsed\n",
      "3101 training examples processsed\n",
      "3201 training examples processsed\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'index' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-421625755696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_embedding_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_flair_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#trop long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-ca897389fcfb>\u001b[0m in \u001b[0;36mfeatures_flair_embeddings\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mdocument_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rousselpaul/anaconda/lib/python3.6/site-packages/flair/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text, use_tokenizer, labels)\u001b[0m\n\u001b[1;32m    336\u001b[0m                         \u001b[0mword\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mchar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0;31m# increment for last token in sentence if not followed by whtespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'index' referenced before assignment"
     ]
    }
   ],
   "source": [
    "features_embedding_content = features_flair_embeddings(df['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
